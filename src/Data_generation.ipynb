{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is to downlod user tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter tweet download to call API\n",
    "from twitter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from os.path import join\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import preprocessor # Twitter pre-processor\n",
    "\n",
    "# language detection\n",
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API a/c details\n",
    "\n",
    "key = \"\"\n",
    "secret = \"\"\n",
    "token=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Twitter object to download the tweets\n",
    "\n",
    "twitter = Twitter(auth = OAuth(\"\",\n",
    "                  \"\",\n",
    "                  \"\",\n",
    "                  \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweets_map = {}\n",
    "twitter_errors = []\n",
    "total_request_made = 0\n",
    "total_request_limit = 90000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download user tweets using twtter object\n",
    "\n",
    "def get_all_tweets(user_id, total_request_made):\n",
    "    total_results = []\n",
    "    results = twitter.statuses.user_timeline(user_id = user_id, count = 200)\n",
    "    total_results.extend(results)\n",
    "    if len(results) == 0:\n",
    "        return total_results\n",
    "    \n",
    "    last_id = results[-1]['id']\n",
    "\n",
    "    while last_id != None:\n",
    "        try:\n",
    "            results = twitter.statuses.user_timeline(user_id = user_id, count = 200, max_id = last_id)\n",
    "            total_request_made += 1\n",
    "        except TwitterHTTPError as error:\n",
    "            twitter_errors.append(error)\n",
    "        \n",
    "        if len(results) == 0:\n",
    "            last_id = None\n",
    "        elif last_id == results[-1]['id']:\n",
    "            last_id = None\n",
    "        else:\n",
    "            last_id = results[-1]['id']\n",
    "            total_results.extend(results)\n",
    "    \n",
    "    return total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders=['male','female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset\n",
    "\n",
    "def get_user_tweets():\n",
    "    t0 = time()\n",
    "    csv_path = \"C:\\\\Users\\\\pvashisth\\\\Desktop\\\\ai_course\\\\Git\\\\twitter-gender-classification\\\\src\\\\data.csv\"\n",
    "    \n",
    "    df = pd.read_csv(csv_path, encoding='latin-1')\n",
    "    \n",
    "    df = df.loc[(df['gender'].isin(genders)) & (df['gender:confidence'] == 1)]\n",
    "    print(df.shape)\n",
    "    \n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        if total_request_made >= total_request_limit:\n",
    "            print(\"Stopping for today!!!!\")\n",
    "            print(\"Next user to be processed is {}: \".format(row['user_id']))\n",
    "            return\n",
    "        try:\n",
    "            results = get_all_tweets(row['user_id'], total_request_made)\n",
    "        except TwitterHTTPError as error:\n",
    "            twitter_errors.append(error)\n",
    "        \n",
    "        user_tweets_map[row['user_id']] = {\n",
    "            'gender': row['gender'],\n",
    "            'results': results\n",
    "        }\n",
    "    \n",
    "    # save the dict.\n",
    "    with open(join('C:\\\\Users\\\\pvashisth\\\\Desktop\\\\ai_course\\\\Git\\\\twitter-gender-classification\\\\src', 'user_all_tweets_data_part_1'), 'w', encoding='utf-8') as w:\n",
    "        json.dump(user_tweets_map, w)\n",
    "    \n",
    "    print(\"Completed in {}\".format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10020, 26)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fb3daf49ea4b55b0aefdceaab7d923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 3792.848995447159\n"
     ]
    }
   ],
   "source": [
    "get_user_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10020"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_tweets_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(user_tweets_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per user tweet Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tweets = []\n",
    "for utm in user_tweets_map:\n",
    "    total_tweets.append(len(user_tweets_map[utm]['results']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10020"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34.56217564870259, 0.0, 272.40745141659124, 0, 3218)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data analysis of per user tweet\n",
    "\n",
    "np.mean(total_tweets), np.median(total_tweets), np.std(total_tweets), np.min(total_tweets), np.max(total_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation (cleaning, data analysis- creating dataset to train ML model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweets_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\pvashisth\\\\Desktop\\\\ai_course\\\\Git\\\\twitter-gender-classification\\\\src\\\\user_all_tweets_data_part_1\", 'r') as r:\n",
    "    user_tweets_map = json.loads(r.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10020"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_tweets_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_tweets_map['815719226']['results'][0]['text'].split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_lengths = []\n",
    "for user_id in user_tweets_map:\n",
    "    tweets_data = user_tweets_map[user_id]['results']\n",
    "    \n",
    "    for tweet in tweets_data:\n",
    "        tweets_lengths.append(len(tweet['text'].split())) # text property contains the acutal tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346313"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.082344584234493, 11.0, 6.738272884423014, 1, 53)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tweets_lengths), np.median(tweets_lengths), np.std(tweets_lengths), np.min(tweets_lengths), np.max(tweets_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering tweets by words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 27, 1065, 58183, 199659, 302549)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_than_50 = [t for t in tweets_lengths if t >=50]\n",
    "more_than_40 = [t for t in tweets_lengths if t >=40]\n",
    "more_than_30 = [t for t in tweets_lengths if t >=30]\n",
    "more_than_20 = [t for t in tweets_lengths if t >=20]\n",
    "more_than_10 = [t for t in tweets_lengths if t >=10]\n",
    "more_than_5 = [t for t in tweets_lengths if t >=5]\n",
    "\n",
    "len(more_than_50), len(more_than_40), len(more_than_30), len(more_than_20), len(more_than_10), len(more_than_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "dataset['male'] = []\n",
    "dataset['female'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets cleaning using the python package 'Pre-Processor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets_for_user(results):\n",
    "    tweets = []\n",
    "    for tweet_entry in results:\n",
    "        tweet = tweet_entry['text']\n",
    "        tweet = preprocessor.clean(tweet)\n",
    "        \n",
    "        tweets.append(tweet)\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user_id in user_tweets_map:\n",
    "    gender = user_tweets_map[user_id]['gender']\n",
    "    \n",
    "    if gender == 'male':\n",
    "        dataset['male'].extend(get_tweets_for_user(user_tweets_map[user_id]['results']))\n",
    "    elif gender == 'female':\n",
    "        dataset['female'].extend(get_tweets_for_user(user_tweets_map[user_id]['results']))\n",
    "    else:\n",
    "        raise Exception(\"blah blah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163655, 182658)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['male']), len(dataset['female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_tweets = dataset['male']\n",
    "female_tweets = dataset['female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5, 274, 19387, 80620, 132497)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_than_50 = [t for t in male_tweets if len(t.split()) >=50]\n",
    "more_than_40 = [t for t in male_tweets if len(t.split()) >=40]\n",
    "more_than_30 = [t for t in male_tweets if len(t.split()) >=30]\n",
    "m_more_than_20 = [t for t in male_tweets if len(t.split()) >=20]\n",
    "more_than_10 = [t for t in male_tweets if len(t.split()) >=10]\n",
    "more_than_5 = [t for t in male_tweets if len(t.split()) >=5]\n",
    "\n",
    "len(more_than_50), len(more_than_40), len(more_than_30), len(m_more_than_20), len(more_than_10), len(more_than_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "': My story, please go for your smears ladies BR - News - Cervical Cancer survivor tell her story'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_tweets[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 7, 384, 22545, 93416, 148373)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_than_50 = [t for t in female_tweets if len(t.split()) >=50]\n",
    "more_than_40 = [t for t in female_tweets if len(t.split()) >=40]\n",
    "more_than_30 = [t for t in female_tweets if len(t.split()) >=30]\n",
    "f_more_than_20 = [t for t in female_tweets if len(t.split()) >=20]\n",
    "more_than_10 = [t for t in female_tweets if len(t.split()) >=10]\n",
    "more_than_5 = [t for t in female_tweets if len(t.split()) >=5]\n",
    "\n",
    "len(more_than_50), len(more_than_40), len(more_than_30), len(f_more_than_20), len(more_than_10), len(more_than_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9762\n",
      "278.7980568408966\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "male_english_tweets = []\n",
    "for mt in m_more_than_20:\n",
    "    doc = nlp(mt)\n",
    "    \n",
    "    if doc._.language['language'] == 'en':\n",
    "        male_english_tweets.append(mt)\n",
    "    \n",
    "print(len(male_english_tweets))\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11259\n",
      "341.67352747917175\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "female_english_tweets = []\n",
    "for ft in f_more_than_20:\n",
    "    doc = nlp(ft)\n",
    "    \n",
    "    if doc._.language['language'] == 'en':\n",
    "        female_english_tweets.append(ft)\n",
    "    \n",
    "print(len(female_english_tweets))\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9762, 11259)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(male_english_tweets), len(female_english_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the english tweets as tsv and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, f in enumerate(male_english_tweets):\n",
    "    with open(join(\"C:\\\\Users\\\\pvashisth\\\\Desktop\\\\ai_course\\\\Git\\\\twitter-gender-classification\\\\src\\\\Data\\\\pos\", str(index) + \".txt\"), 'w', encoding='utf-8') as w:\n",
    "        w.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, f in enumerate(female_english_tweets):\n",
    "    with open(join(\"C:\\\\Users\\\\pvashisth\\\\Desktop\\\\ai_course\\\\Git\\\\twitter-gender-classification\\\\src\\\\Data\\\\neg\", str(index) + \".txt\"), 'w', encoding='utf-8') as w:\n",
    "        w.write(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
